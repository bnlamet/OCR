# OCR
Optical Character Recognition project coded for Introduction to Computer Science II course. The project description is as follows:

We humans are quite good at generalizing. We can look at text that’s on a page that is splattered with mud (or, more likely, coffee), and we can most likely read the text. We can read text that has been ripped, crumpled, faded, and even worn off the page. We’re that good. Computers, however, struggle with the problem of generalizing. And yet it is necessary to be able to take a page with text on it and to scan it in and convert it into recognized characters and words. Think of all the medical records that are currently sitting in files in medical offices. What if you need to know whether your mom was ever vaccinated against whooping cough? What if the CDC wants to determine if there’s an outbreak of a particular syndrome or type of cancer in a particular region of the country? Equally, many law offices need to scan in old cases and conclusions (clearly I’m not a lawyer – I’m not using the correct terminology) so that when researching current cases they can refer to previous conclusions to support their case. I’ve dealt extensively with the problem of scanning in documents and converting them into a form that can be used in a word processor (and hence read by a screen reader) when dealing with students who are blind or just nonvisual readers. These students regularly get handouts from professors who’ve had an article they’ve been Xeroxing since the 80’s. Without the ability to scan in the paper and then convert it to a form that can be read by a screenreader, the handout is the equivalent of a blank paper to these students.
The problem of taking text on a physical page and digitizing it and converting it into characters recognized by the computer is known as OCR – Optical Character Recognition. It usually consists of two parts: Taking a page and scanning it in to the computer (i.e., digitizing the page); and then taking the scanned in image and locating characters within the scanned in page. When the page is first scanned into the computer, it is usually a bitmapped image of the page – just numbers representing the amount of color at every dot on the page. At this point, the computer has no idea what characters may be on the page. OCR involves looking at the dots of color within the scanned image and trying to find patterns of color, and then relate those patterns to patterns of images.
Initially, OCR was done using individual files, with each file holding a pattern for a particular character in a particular font. While this can clearly get out of hand quickly (think of the number of fonts you have on your computer alone, and then throw in individual handwriting), we still use this method for certain problems in which we know the font that will be used. More frequently today we use a more sophisticated system of looking for characteristic patterns that represent characters. For instance, a
capital letter A would be represented by 3 patterns – a forward slant, a backwards slant, and a horizontal line occurring between the top and bottom of the forward slant and backward slant.
Your problem:
The post office only has to identify zip codes. Thus their problem is limited to 10 characters – 0 through 9. For simplicity’s sake, that’s what we’ll work on. In addition, we’ll assume that every character is in the same font. Thus we have files representing the characters 0 through 9 (named zero.txt, one.txt, two.txt, etc.). These will be the files that will be used to identify characters in the various image files (You can download each of these number files from my web site. Store them in your OCRProj folder (parallel to the src folder)).
The general idea: Both the character files and the image files will be read into matrices (arrays of arrays). The image file will be “cleaned” (converted so that each entry in the matrix will either be considered black (represented by 1) or white (represented by 0). Once the image file is cleaned, each entry in the character file will be compared to each entry in the image file. If the two entries match, the matching score will increase. If they don’t, the score will either drop or stay the same. Thus an overall matching score will be determined for the image file and the character file.
The image file will be compared to all 10 character files. The image will be determined to be the character whose file it best matches.
Note that the image file will be “noisy”, meaning there will be certain dots that will be considered to be black (1) when they are just dirt specs or extra ink, or even just scanned in incorrectly. Equally some dots that should have ink may be considered white (0), possibly because of folds in the paper or over- xeroxing, etc. We’re doing a best match.
